# âš¡ LSTM-Based Time Series Forecasting on Household Power Consumption

> **An end-to-end deep learning project** leveraging LSTM networks for energy demand forecasting, complete with statistical validation, exploratory data analysis (EDA), feature engineering, and explainable AI (SHAP) interpretation.

---

## ğŸ§­ Table of Contents

* [Overview](#-overview)
* [Dataset Description](#-dataset-description)
* [Key Objectives](#-key-objectives)
* [Project Pipeline](#-project-pipeline)
* [Feature Engineering](#-feature-engineering)
* [Exploratory Data Analysis (EDA)](#-exploratory-data-analysis-eda)
* [Model Architecture](#-model-architecture)
* [Evaluation Metrics](#-evaluation-metrics)
* [Model Explainability (SHAP)](#-model-explainability-shap)
* [Results & Insights](#-results--insights)
* [Installation & Execution](#-installation--execution)
* [Project Structure](#-project-structure)
* [Future Work](#-future-work)
* [References](#-references)

---

## ğŸ“˜ Overview

This project demonstrates **time series modeling and forecasting** using **Long Short-Term Memory (LSTM)** neural networks on the *Household Power Consumption* dataset.
The pipeline includes:

* Statistical testing (ADF Test, Normality Check)
* Multi-level time aggregation (Daily, Weekly, Monthly)
* Deep Learning Forecasting (LSTM)
* Explainability via **SHAP** (Global & Local Interpretations)

The project bridges **classical statistical analysis** and **modern neural forecasting** to uncover deep insights into household energy patterns.

---

## ğŸ“Š Dataset Description

**Dataset Name:** `household_power_consumption.csv`
**Source:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption)

| Column                | Description                                                                  |
| :-------------------- | :--------------------------------------------------------------------------- |
| `Date`, `Time`        | Timestamp of power readings                                                  |
| `Global_active_power` | Total household active power (kW)                                            |
| Other columns         | Include voltage, current, sub-metering, etc. (optional fields not used here) |

* **Time Period Covered:** Dec 2006 â€“ Nov 2010
* **Sampling Frequency:** 1 minute
* **Data Size:** 2,075,259 rows Ã— 9 columns

---

## ğŸ¯ Key Objectives

1. **Understand** the underlying power consumption patterns.
2. **Preprocess & engineer** temporal and statistical features.
3. **Build and optimize** an LSTM model for sequence prediction.
4. **Quantify performance** using RMSE and MAE metrics.
5. **Interpret model behavior** using SHAP-based explainability.

---

## ğŸ§© Project Pipeline

```
Data Loading â†’ Cleaning â†’ Feature Engineering â†’
EDA â†’ Stationarity Testing â†’ LSTM Modeling â†’
Performance Evaluation â†’ Explainability (SHAP)
```

---

## âš™ï¸ Feature Engineering

Key transformations applied:

| Step               | Transformation                                         |
| ------------------ | ------------------------------------------------------ |
| Timestamp parsing  | Combined `Date` + `Time` â†’ `date_time`                 |
| Numerical cleaning | Converted `Global_active_power` â†’ float; dropped NaNs  |
| Derived features   | Extracted `year`, `quarter`, `month`, `day`, `weekday` |
| Sorting & indexing | Chronologically ordered time series                    |
| Scaling            | `MinMaxScaler(0,1)` for LSTM normalization             |

---

## ğŸ” Exploratory Data Analysis (EDA)

**1. Normality Test (Dâ€™Agostinoâ€™s KÂ²):**

```python
stat, p = stats.normaltest(data.Global_active_power)
```

Result: **Non-Gaussian distribution** â†’ Heavy skew and kurtosis observed.

**2. Visual Insights:**

* Time series plots (2006â€“2008)
* Violin plots across Year & Quarter
* Histograms & Probability plots
* Aggregated daily, weekly, monthly, quarterly, yearly power consumption trends

**3. Stationarity Testing:**
Augmented Dickey-Fuller test confirms **non-stationarity**, justifying LSTM usage.

---

## ğŸ§  Model Architecture

**Model Type:** LSTM (Sequential)

| Layer | Type             | Parameters                        |
| :---- | :--------------- | :-------------------------------- |
| 1     | LSTM (100 units) | Input: (timesteps=30, features=1) |
| 2     | Dropout(0.2)     | Regularization                    |
| 3     | Dense(1)         | Output layer                      |

**Compilation:**

```python
model.compile(loss='mean_squared_error', optimizer='adam')
```

**Training:**

* `epochs=20`
* `batch_size=1240`
* `validation_split=0.2`
* `EarlyStopping(monitor='val_loss', patience=4)`

---

## ğŸ“ˆ Evaluation Metrics

| Metric       | Formula                        | Purpose                      |   |                                   |
| :----------- | :----------------------------- | :--------------------------- | - | --------------------------------- |
| **MAE**      | mean(                          | y_true - y_pred              | ) | Average absolute prediction error |
| **RMSE**     | sqrt(mean((y_true - y_pred)Â²)) | Penalizes larger errors more |   |                                   |
| **RÂ² Score** | Model variance explanation     | Optional (not used here)     |   |                                   |

### Example Output

```
Train MAE: 0.019
Train RMSE: 0.027
Test MAE: 0.021
Test RMSE: 0.029
```

---

## ğŸ§© Model Explainability (SHAP)

Explainability is implemented using both **DeepExplainer** and **KernelExplainer** from the SHAP library.

### Global Feature Importance

`shap.summary_plot()` visualizes the most influential time lags (`t-30` â†’ `t-1`) driving the prediction.

### Local Explanation

`shap.force_plot()` provides **instance-level interpretation** â€” showing which recent values push predictions higher or lower.

These plots transform the model into an **interpretable forecasting tool**, crucial for industrial applications.

---

## ğŸ“Š Results & Insights

âœ… The LSTM model successfully captured temporal dependencies in power usage.
âœ… Strong performance on test data with low RMSE.
âœ… SHAP analysis revealed that **recent 7â€“10 timesteps** most influence next-step predictions.
âœ… Clear seasonal & diurnal patterns were observed in EDA visualizations.

---

## ğŸ§  Future Work

* Implement **Bidirectional LSTM** and **GRU** for comparison.
* Add **external regressors** (temperature, holidays).
* Deploy the model as a **Flask/Streamlit dashboard**.
* Integrate **real-time prediction pipelines** via MQTT or Kafka.

---

## ğŸ§° Installation & Execution

### Prerequisites

* Python â‰¥ 3.8
* Libraries:

  ```bash
  pip install numpy pandas matplotlib seaborn scikit-learn keras tensorflow shap statsmodels
  ```

### Run the Project

```bash
python untitled3.py
```

or in Jupyter/Colab:

```python
!python untitled3.py
```

---

## ğŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ household_power_consumption.csv   # Dataset
â”œâ”€â”€ untitled3.py                      # Main project file
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ requirements.txt                  # Dependencies (optional)
```

---

## ğŸ“š References

* UCI Machine Learning Repository â€” Household Power Consumption Dataset
* Chollet, F. (2015). *Keras: Deep Learning Library for Theano and TensorFlow*
* Lundberg, S. & Lee, S. (2017). *A Unified Approach to Interpreting Model Predictions (SHAP)*
* Hyndman, R. & Athanasopoulos, G. (2018). *Forecasting: Principles and Practice*

---

## ğŸ Author

**Apratim Phadke** and **Ishika Bhad**
ğŸ“§ [GitHub](https://github.com/ApratimPhadke) | ğŸ”— [LinkedIn-Apratim Phadke](https://www.linkedin.com/in/apratim-phadke-966816223/)|
ğŸ”— [LinkedIn-Ishika Bhad](https://www.linkedin.com/in/ishika-bhad-a47ab0295/)

